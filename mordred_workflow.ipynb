{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matina/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/matina/Downloads/ccus_amine_prediction_workflow-main/dask-worker-space/worker-hh1naucl', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/matina/Downloads/ccus_amine_prediction_workflow-main/dask-worker-space/worker-2nb8x9iw', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/matina/Downloads/ccus_amine_prediction_workflow-main/dask-worker-space/worker-6kee6xqi', purging\n",
      "distributed.diskutils - INFO - Found stale lock file and directory '/Users/matina/Downloads/ccus_amine_prediction_workflow-main/dask-worker-space/worker-zt6j2ny9', purging\n"
     ]
    }
   ],
   "source": [
    "# Mordred\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "# Python standard library\n",
    "import os, sys\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Utils\n",
    "sys.path.append(\".\")\n",
    "from utils import classification_metrics as cmetrics\n",
    "from utils import finger_prints as fp\n",
    "from utils import classification_workflow_functions as cwf\n",
    "\n",
    "import logging \n",
    "logging.basicConfig(format='%(message)s')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.ERROR)\n",
    "\n",
    "from dask.distributed import Client\n",
    "try:\n",
    "    client.shutdown()\n",
    "except NameError:\n",
    "    log.info(\"No client already active\")\n",
    "\n",
    "client = Client(dashboard_address=\":8855\")\n",
    "log.info(\"Dask clinet on localhost:8855\")\n",
    "\n",
    "random_seed = 10459\n",
    "np.random.seed = random_seed\n",
    "np.random.RandomState(random_seed)\n",
    "log.info(f\"Random seed fixed as {random_seed} current working dir {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results_mordred\", exist_ok=True)\n",
    "os.chdir(\"results_mordred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ccs-98.csv\", sep=\";\")\n",
    "data.columns = [\"_\".join(ent.lower().strip().split(\" \")) for ent in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = data[\"smiles\"]\n",
    "log.info(\"SMILES: {}\".format(smiles.head()))\n",
    "\n",
    "names = data[\"label\"]\n",
    "log.info(\"Names: {}\".format(names.head()))\n",
    "\n",
    "number_of_n_atoms = data[\"n_nitrogen\"].astype(\"int\")\n",
    "log.info(\"Number of N atoms: {}\".format(number_of_n_atoms.head()))\n",
    "\n",
    "amines_mass_mr = data[\"molecular_mass\"].astype(\"float64\")\n",
    "pd.to_numeric(amines_mass_mr, errors=\"coerce\")\n",
    "log.info(\"Amines mass Mr: {}\".format(amines_mass_mr.head()))\n",
    "\n",
    "molco2_moln = data[\"capacity_molco2_molamime\"]\n",
    "pd.to_numeric(molco2_moln, errors=\"coerce\")\n",
    "log.info(\"molCO2_molN: {}\".format(molco2_moln.head()))\n",
    "\n",
    "initial_rates = data[\"rate_molco2_molamime_min\"]\n",
    "pd.to_numeric(initial_rates, errors=\"coerce\")\n",
    "log.info(\"initial_rates: {}\".format(initial_rates.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Target Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = molco2_moln\n",
    "target_name = \"capacity (molCO2 / molN)\"\n",
    "target_key = \"capacity_molco2_molamime\"\n",
    "units = \"molco2_moln\"\n",
    "threshold_for_catagorical = 50.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Mordred Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 98/98 [00:03<00:00, 24.69it/s]\n"
     ]
    }
   ],
   "source": [
    "calc = Calculator(descriptors, ignore_3D=False)\n",
    "molecule_list = [cwf.get_mol_from_smiles(s) for s in smiles]\n",
    "features_df = calc.pandas(molecule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>...</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.887564</td>\n",
       "      <td>7.393377</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.796486</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>48.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.972222</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.656854</td>\n",
       "      <td>5.427660</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.424292</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.140017</td>\n",
       "      <td>6.387892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.943722</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>48.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>1.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.949747</td>\n",
       "      <td>5.531236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.445871</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.426503</td>\n",
       "      <td>5.655215</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.312845</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>1.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABC     ABCGG  nAcid  nBase    SpAbs_A  ...  WPol  Zagreb1  Zagreb2  \\\n",
       "0  7.887564  7.393377      0      1  13.796486  ...    11     48.0     51.0   \n",
       "1  5.656854  5.427660      0      1  10.424292  ...     7     34.0     36.0   \n",
       "2  7.140017  6.387892      0      1  11.943722  ...    10     48.0     56.0   \n",
       "3  4.949747  5.531236      0      1   9.445871  ...     7     28.0     28.0   \n",
       "4  5.426503  5.655215      0      1   8.312845  ...     5     32.0     30.0   \n",
       "\n",
       "   mZagreb1  mZagreb2  \n",
       "0  3.972222  2.666667  \n",
       "1  2.611111  2.000000  \n",
       "2  2.583333  1.944444  \n",
       "3  4.111111  2.250000  \n",
       "4  4.812500  1.875000  \n",
       "\n",
       "[5 rows x 1826 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.dropna(inplace=True, thresh=int(0.9*len(features_df.index)))\n",
    "threshold = 0.5\n",
    "features_df.drop(features_df.std()[features_df.std() < threshold].index.values, axis=1)\n",
    "features_df.columns = [ent.strip() for ent in features_df.columns]\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(features_df)\n",
    "feature_types = \"no_catagorical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(\"mordred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate significant featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reasonable_predicted_properties, significant_fearures = cwf.find_correlating_features(features_df, targets, thresh=0.5, \n",
    "                                                                                      plot=False, corr_method=\"spearman\", \n",
    "                                                                                      sig_metric=\"spearman\", process_non_numeric=True, \n",
    "                                                                                      sig_level=0.05, significance=True, n_sample=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"{} {}\".format(reasonable_predicted_properties, len(reasonable_predicted_properties)))\n",
    "log.info(\"{} {}\".format(significant_fearures, len(significant_fearures)))\n",
    "use_significant = True\n",
    "use_reasonable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = pd.DataFrame()\n",
    "\n",
    "if use_significant is True:\n",
    "    for k in significant_fearures:\n",
    "        feats_df[k] = features_df[k]\n",
    "        \n",
    "elif use_reasonable is True:\n",
    "    for k in reasonable_predicted_properties:\n",
    "        feats_df[k] = features_df[k]\n",
    "        \n",
    "feats_df.to_csv(\"mordred-features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATS2dv</th>\n",
       "      <th>AATS0dv</th>\n",
       "      <th>AATS1dv</th>\n",
       "      <th>AATS2dv</th>\n",
       "      <th>AATS0Z</th>\n",
       "      <th>...</th>\n",
       "      <th>AETA_eta_F</th>\n",
       "      <th>ETA_epsilon_1</th>\n",
       "      <th>PEOE_VSA2</th>\n",
       "      <th>SlogP_VSA6</th>\n",
       "      <th>AMW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.964286</td>\n",
       "      <td>1.849057</td>\n",
       "      <td>17.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296479</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.683069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.575000</td>\n",
       "      <td>16.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211642</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.480939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>2.304348</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226664</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.777260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.956522</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>14.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257138</td>\n",
       "      <td>0.489855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.091972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.956522</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>14.956522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226809</td>\n",
       "      <td>0.489855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.091972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>21.846154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646672</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.395945</td>\n",
       "      <td>7.234854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>5.636364</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>19.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422872</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>19.599639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.368463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>200.111111</td>\n",
       "      <td>8.706790</td>\n",
       "      <td>2.281481</td>\n",
       "      <td>8.337963</td>\n",
       "      <td>38.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553430</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>4.523747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.813693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545032</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>4.676102</td>\n",
       "      <td>24.526421</td>\n",
       "      <td>6.837758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668100</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>4.983979</td>\n",
       "      <td>18.590531</td>\n",
       "      <td>7.920696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ATS2dv   AATS0dv   AATS1dv   AATS2dv     AATS0Z  ...  AETA_eta_F  \\\n",
       "0    98.000000  4.000000  2.964286  1.849057  17.214286  ...    0.296479   \n",
       "1    63.000000  3.333333  2.571429  1.575000  16.285714  ...    0.211642   \n",
       "2   106.000000  4.000000  3.478261  2.304348  17.181818  ...    0.226664   \n",
       "3    42.000000  2.956522  2.181818  1.050000  14.956522  ...    0.257138   \n",
       "4    41.000000  2.956522  2.272727  1.025000  14.956522  ...    0.226809   \n",
       "..         ...       ...       ...       ...        ...  ...         ...   \n",
       "93   96.000000  6.615385  6.615385  5.052632  21.846154  ...    0.646672   \n",
       "94  198.000000  5.636364  5.000000  4.125000  19.272727  ...    0.422872   \n",
       "95  200.111111  8.706790  2.281481  8.337963  38.125000  ...    0.553430   \n",
       "96   75.000000  5.833333  6.000000  4.166667  20.666667  ...    0.545032   \n",
       "97  110.000000  8.500000  8.166667  6.470588  24.666667  ...    0.668100   \n",
       "\n",
       "    ETA_epsilon_1  PEOE_VSA2  SlogP_VSA6       AMW  \n",
       "0        0.526190   0.000000    0.000000  5.683069  \n",
       "1        0.507937   0.000000    0.000000  5.480939  \n",
       "2        0.516667   0.000000    0.000000  5.777260  \n",
       "3        0.489855   0.000000    0.000000  5.091972  \n",
       "4        0.489855   0.000000    0.000000  5.091972  \n",
       "..            ...        ...         ...       ...  \n",
       "93       0.576923   0.000000   24.395945  7.234854  \n",
       "94       0.554545  19.599639    0.000000  6.368463  \n",
       "95       0.704167   4.523747    0.000000  8.813693  \n",
       "96       0.566667   4.676102   24.526421  6.837758  \n",
       "97       0.633333   4.983979   18.590531  7.920696  \n",
       "\n",
       "[98 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_amine_counts</th>\n",
       "      <th>secondary_amine_counts</th>\n",
       "      <th>tertiary_amine_counts</th>\n",
       "      <th>aromatic_sp2_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>primary_amine_counts</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169055</td>\n",
       "      <td>0.169133</td>\n",
       "      <td>-0.089662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondary_amine_counts</th>\n",
       "      <td>0.169055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>-0.121115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tertiary_amine_counts</th>\n",
       "      <td>0.169133</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.162201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aromatic_sp2_n</th>\n",
       "      <td>-0.089662</td>\n",
       "      <td>-0.121115</td>\n",
       "      <td>-0.162201</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        primary_amine_counts  secondary_amine_counts  \\\n",
       "primary_amine_counts                1.000000                0.169055   \n",
       "secondary_amine_counts              0.169055                1.000000   \n",
       "tertiary_amine_counts               0.169133                0.041569   \n",
       "aromatic_sp2_n                     -0.089662               -0.121115   \n",
       "\n",
       "                        tertiary_amine_counts  aromatic_sp2_n  \n",
       "primary_amine_counts                 0.169133       -0.089662  \n",
       "secondary_amine_counts               0.041569       -0.121115  \n",
       "tertiary_amine_counts                1.000000       -0.162201  \n",
       "aromatic_sp2_n                      -0.162201        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = []\n",
    "for ith, s in enumerate(smiles):\n",
    "    n_primary, n_secondary, n_tertiary, n_aromaticsp2 = cwf.count_amine_types(s, show=False)\n",
    "    counts.append([n_primary, n_secondary, n_tertiary, n_aromaticsp2])\n",
    "    log.debug(\"\\n{}; number of primary: {} number of secondary: {} number of tertiary: {} number of aromatic sp2 nitrogen atoms: {}\\nsmiles {}\". format(ith, n_primary, n_secondary, n_tertiary, n_aromaticsp2, s))\n",
    "\n",
    "df = pd.DataFrame(data=counts, columns=[\"primary_amine_counts\",\"secondary_amine_counts\", \"tertiary_amine_counts\", \"aromatic_sp2_n\" ])\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if target_name == \"initial_rate\":\n",
    "    log.info(\"Initial rate class\")\n",
    "    mean = np.mean(initial_rates)\n",
    "    stdev = np.std(initial_rates)\n",
    "    class_thresh = mean + stdev\n",
    "    log.info(\"mean {} standard deviation {} class threshold {}\".format(mean, stdev, class_thresh))\n",
    "    classes = []\n",
    "    for i in initial_rates:\n",
    "        if i < class_thresh:\n",
    "            classes.append(0)\n",
    "        else:\n",
    "            classes.append(1)\n",
    "    log.info(\"Number of classes: {}  Number of class 1: {} number of class 0: {}\".format(len(classes), len([x for x in classes if x == 1]), len([x for x in classes if x == 0])))\n",
    "    class_targets_df = pd.DataFrame(np.array([classes]).T, columns=[\"classes\"])\n",
    "    features_and_classes_df = features_df.copy()\n",
    "    features_and_classes_df[\"classes\"] = classes\n",
    "    \n",
    "else:\n",
    "    log.info(\"Capture capacity class\")\n",
    "    classes = cwf.capacity_classes(df[\"primary_amine_counts\"].values, df[\"secondary_amine_counts\"].values, df[\"tertiary_amine_counts\"].values, df[\"aromatic_sp2_n\"].values, targets,\n",
    "                         units=units, number_of_N_atoms=number_of_n_atoms, amines_mr=amines_mass_mr)\n",
    "    log.info(classes)\n",
    "    log.info(\"Number of classes: {}  Number of class 1: {} number of class 0: {}\".format(len(classes), len([x for x in classes if x == 1]), len([x for x in classes if x == 0])))\n",
    "\n",
    "    class_targets_df = pd.DataFrame(np.array([classes]).T, columns=[\"classes\"])\n",
    "    features_and_classes_df = features_df.copy()\n",
    "    features_and_classes_df[\"classes\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_for_catagorical = 50.0\n",
    "log.info(\"Threshold for a catagorical feature is any feature where more than {}% of the point have have a value or all vlaues are separated by the same step size\".format(threshold_for_catagorical))\n",
    "catagorical_name = []\n",
    "catagorical_indx = []\n",
    "for ith, column in enumerate(feats_df.columns):\n",
    "    if column != \"training\":\n",
    "        vals = sorted(set(feats_df[column].values))\n",
    "        steps = [elt - eltp1 for elt, eltp1 in zip(vals, vals[1:])]\n",
    "        log.debug(f\"\\n{ith} {column}\\n{steps}\\n\")\n",
    "        percent = []\n",
    "        for step in steps:\n",
    "            percent.append(len([elt for elt in steps if elt == step])/len(steps) * 100.0)\n",
    "        log.debug(f\"percentage {ith} {column}: {percent}\\n\")\n",
    "\n",
    "        if any(elt >= threshold_for_catagorical for elt in percent):\n",
    "            log.info(\"More than {} point have the same value for {} {}\".format(threshold_for_catagorical, ith, column))\n",
    "            catagorical_indx.append(ith)\n",
    "            catagorical_name.append(column)\n",
    "        elif all(elt == steps[0] for elt in steps):\n",
    "            log.info(\"Same separating step size for all features in {} {}\".format(ith, column))\n",
    "\n",
    "log.info(catagorical_indx)\n",
    "log.info(catagorical_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = feats_df.columns\n",
    "mordred_features_df = pd.DataFrame(data=np.array([[i+1 for i in range(len(feats))], feats]).T, columns=[\"Index\", \"Feature\"])\n",
    "with open(\"modred_{}_feature.tex\".format(len(feats)), \"w\") as fout:\n",
    "    mordred_features_df.to_latex(fout, float_format=\"{:0.2f}\".format, position=\"H\", longtable=True, caption=\"Feature selected from Spearman correlation coefficient (\\textgreater 0.4) and two tail p test at 95\\%\", label=\"tbl:fingerprint_{}_features\".format(len(feats)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df_bkup = feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx, f in enumerate(feats):\n",
    "    log.info(f\"-----\\nIndex: {inx}\\n{feats_df[f].values}\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dc/587y55y97v7fzbkqycm2n61h0000gn/T/ipykernel_7697/3589516091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mfeats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    673\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my-rdkit-env/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (98, 84), indices imply (98, 35)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dc/587y55y97v7fzbkqycm2n61h0000gn/T/ipykernel_7697/3589516091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mfeats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mfeats_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"catagorical indexes {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatagorical_indxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_array'"
     ]
    }
   ],
   "source": [
    "feature_types = \"some_catagorical\"\n",
    "# NOTE: USER DEFINES THE LIST BELOW!!!!!!\n",
    "catagorical_indxs = [18, 19, 20, 21, 22, 28]\n",
    "# [0, 1, 2, 5, 6, 7, 8, 9, 10,14, 15, 20, 31, 32, 33, 34]\n",
    "# 0.6 [0, 1, 2, 3, 4]\n",
    "# 0.5 [0, 1, 2, 5, 6, 7, 8, 9, 10,14, 15, 20, 31, 32, 33, 34]\n",
    "# 0.4 [0, 1, 2, 25, 26, 27, 29, 30, 31, 32, 39, 40, 41, 47, 72, 73, 74, 75]\n",
    "# 0.4 old [0, 1, 2, 21, 22, 23, 25, 26, 35, 36, 37, 41, 43, 68, 69, 70, 71]\n",
    "feature_columns = feats_df.columns\n",
    "\n",
    "# Backup\n",
    "backup_feats_df = feats_df.copy()\n",
    "\n",
    "# None catagorical only scale the data as numbers\n",
    "if feature_types == \"no_catagorical\":\n",
    "    mm_scaler = MinMaxScaler()\n",
    "    feats_df = mm_scaler.fit_transform(feats_df)\n",
    "    log.info(pd.DataFrame(feats_df, columns=feature_columns))\n",
    "    feats_df = pd.DataFrame(feats_df, columns=feature_columns)\n",
    "    \n",
    "# Some catagorical - Need to provide the indexes\n",
    "elif feature_types == \"some_catagorical\":\n",
    "    numeric_features = [feature_columns[i] for i in range(len(feature_columns)) if i not in catagorical_indxs]\n",
    "    numerical_transformer = MinMaxScaler()\n",
    "    categorical_features = [feature_columns[i] for i in range(len(feature_columns)) if i in catagorical_indxs]\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    if any(ent in categorical_features for ent in numeric_features):\n",
    "        log.warning(\"WARNING - numeric and catagorical feature specififed overlap\")\n",
    "        log.info(numeric_features)\n",
    "        log.info(categorical_features)\n",
    "    else:\n",
    "        log.info(\"Numerical features:\\n{} {}\".format(numeric_features, len(numeric_features)))\n",
    "        log.info(\"Catagorical features:\\n{} {}\".format(categorical_features, len(catagorical_indxs)))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", numerical_transformer, numeric_features),\n",
    "        ('catagorical', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    feats_df = preprocessor.fit_transform(feats_df)\n",
    "    feature_names = cwf.get_feature_names_from_column_transformers(preprocessor)\n",
    "    catagorical_indxs = [i for i in range(len(numeric_features), len(feature_names))]\n",
    "    log.info(feature_names)\n",
    "\n",
    "    log.info(type(feats_df))\n",
    "    try:\n",
    "        log.info(pd.DataFrame(feats_df, columns=feature_names))\n",
    "        feats_df = pd.DataFrame(feats_df, columns=feature_names)\n",
    "    except ValueError:\n",
    "        log.info(pd.DataFrame(feats_df.to_array(), columns=feature_names))\n",
    "        feats_df = pd.DataFrame(feats_df.to_array(), columns=feature_names)\n",
    "    log.info(\"catagorical indexes {}\".format(catagorical_indxs))\n",
    "    log.info(\"Catagorical features start on column name {} and end on {}\".format(feats_df.columns[catagorical_indxs[0]], feats_df.columns[catagorical_indxs[-1]]))\n",
    "    \n",
    "# All catagorical\n",
    "elif feature_types == \"catagorical\":\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    feats_df = categorical_transformer.fit_transform(feats_df).toarray()\n",
    "    feature_names = [categorical_transformer.get_feature_names(feature_columns)]\n",
    "    feats_df = pd.DataFrame(feats_df, columns=feature_names)\n",
    "    log.info(feats_df)\n",
    "\n",
    "# No scaling or other encoding\n",
    "else:\n",
    "    log.info(\"No scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_indexes = [ith for ith in range(0, catagorical_indxs[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df.to_csv(\"mordred_scaled_onehotencode_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.DataFrame(data=classes, columns=[\"classes\"])\n",
    "log.info(\"Number in class 0: {}\\nNumber in class 1: {}\\nNumber of examples: {}\".format(\n",
    "    len([ith for ith in classes if ith == 0]), \n",
    "    len([ith for ith in classes if ith == 1]), len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold_clf_names = [\"AdaBoost\",\"Logistic Regression\", \"Gaussian Process\"]\n",
    "\n",
    "kfold_classifiers = [\n",
    "    AdaBoostClassifier(random_state=random_seed),\n",
    "    LogisticRegression(random_state=random_seed, n_jobs=-1, solver=\"lbfgs\"),\n",
    "    GaussianProcessClassifier(random_state=random_seed, n_jobs=-1)\n",
    "]\n",
    "\n",
    "kfold_classifier_parameters = {\n",
    "    \"AdaBoost\": {\"n_estimators\": [10, 20, 50, 100]},\n",
    "    \"Logistic Regression\": {\"penalty\":[\"l2\", \"none\"], \"C\": [0.05, 0.1, 0.25, 0.5, 1.0, 1.25]},\n",
    "    \"Gaussian Process\": {\"kernel\":[1.0 * Matern(length_scale=1.0, nu=1.5), 1.0 * Matern(length_scale=1.0, nu=2.5), 1.0 * RBF(1.0),  1.0 * RBF(1.0) + WhiteKernel(noise_level=0.5)]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ith, ent in enumerate(feats_df.isnull().sum().values):\n",
    "    if ent != 0:\n",
    "        log.info(f\"Row {ith} is not free of nulls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwf.kfold_test_imbalenced_classifiers_with_optimization(feats_df, classes_df, kfold_classifiers, kfold_classifier_parameters, \n",
    "                                                        overwrite=True, scale=False, cv=10, n_repeats=5, smiles=smiles, names=names,\n",
    "                                                        random_seed=random_seed, clf_names=kfold_clf_names, class_labels=(0,1),\n",
    "                                                        smote=True, smote_catagorical_indexes=catagorical_indxs, \n",
    "                                                        smote_continuous_indexes=continous_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_clf_names = [\"AdaBoost\",\"Logistic Regression\", \"Gaussian Process\"]\n",
    "directory_names = cwf.directory_names_from_classfier_names(kfold_clf_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_plt = []\n",
    "\n",
    "for ith, dirname in enumerate(directory_names):\n",
    "    log.info(\"\\n{}\\n-------------\\n\".format(dirname))\n",
    "    data = cwf.build_data_from_directory(dirname, max_folds=5)\n",
    "    \n",
    "    log.debug(\"Last value in the data frame: {}\".format(data[165:166]))\n",
    "    \n",
    "    probs = data[[\"prob0\", \"prob1\"]].to_numpy()\n",
    "    log.debug(\"Probablities for a few examples {}\".format(probs[0:3,0:2]))\n",
    "    \n",
    "    cm = cmetrics.get_confusion_matrix(data, predicted_column_name=\"prediction\", known_column_name=\"known\", return_dict=False)\n",
    "    log.debug(\"Confusion matrix for {}\\n{}\".format(dirname, cm))\n",
    "    \n",
    "    plt_name = \"capacity_{}_mordred.png\".format(\"_\".join([ent.lower() for ent in dirname.split()]))\n",
    "    files_plt.append(plt_name)\n",
    "    log.info(\"Saving plot to {}\\n{}\".format(plt_name, files_plt))\n",
    "    metrics = cmetrics.calculate_confusion_based_metrics(df=data, probabilities=probs, col_map=\"hsv\", positive_label=1, \n",
    "                                                         plt_filename=plt_name, all_classes=False, get_roc_curve=True, \n",
    "                                                         get_pr_curve=False, annotate=True, vmin=0, vmax=85,\n",
    "                                                         title=\"{}\".format(kfold_clf_names[ith]))\n",
    "    #log.info(\"{}\".format(\"\\n\".join([\"{}: {}\".format(k, v) for k, v in metrics.items()])))\n",
    "    \n",
    "    metrics_for_paper = {\n",
    "    \"accuracy\": metrics[\"accuracy\"],\n",
    "    \"sensitivity\": metrics[\"tpr\"],\n",
    "    \"specificity\": metrics[\"tnr\"],\n",
    "    \"mcc\": metrics[\"matthews_correlation_coefficient\"],\n",
    "    \"precision\": metrics[\"precision\"],\n",
    "    \"g-mean\": metrics[\"g-mean\"]\n",
    "    }\n",
    "    \n",
    "    if ith == 0:\n",
    "        df_metrics_for_paper = pd.DataFrame(data=metrics_for_paper, index=[kfold_clf_names[ith].lower()])\n",
    "    else:\n",
    "        df_metrics_for_paper = df_metrics_for_paper.append(pd.Series(metrics_for_paper, name=kfold_clf_names[ith].lower()))\n",
    "    log.debug(df_metrics_for_paper)\n",
    "\n",
    "with open(\"capacity_metrics_mordred.tex\", \"w\") as fout:\n",
    "    cap = \"Classifier metrics for balanced data for capacity with models built from mordred features. MCC is the Matthew’s correlation coefficent.\"\n",
    "    df_metrics_for_paper.to_latex(fout, float_format=\"{:0.2f}\".format, position=\"H\", caption=cap, label=\"tbl:mordred_features\")\n",
    "log.info(df_metrics_for_paper.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimp = pd.read_csv(\"importance_lr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimp_mean = fimp.mean(axis=0)\n",
    "means = fimp_mean.values\n",
    "fimp_means = pd.DataFrame(means).transpose()\n",
    "fimp_means.columns=feats_df.columns\n",
    "\n",
    "fimp_sigma = fimp.std(axis=0)\n",
    "sigmas = fimp_sigma.values\n",
    "fimp_sigmas = pd.DataFrame(sigmas).transpose()\n",
    "fimp_sigmas.columns=feats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(\" \".join(ent.split(\"_\"))) for ent in fimp_means.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(25,20))\n",
    "plt.bar(x=[\" \".join(ent.split(\"_\")) for ent in fimp_means.columns], \n",
    "        height=fimp_means.iloc[0,:].values, \n",
    "        width=1.0,\n",
    "        edgecolor=\"k\",\n",
    "        align=\"edge\")\n",
    "bins = np.arange(len(fimp_means.columns))\n",
    "plt.xlim([0,bins.size])\n",
    "plt.xlabel(\"Feature\", fontsize=35)\n",
    "plt.ylabel(\"Mean Coefficent value\", fontsize=35)\n",
    "plt.xticks(rotation=90, fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title(\"Logistic Regression Mean Feature Importance using Mordred fingerprints\", fontsize=35)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance_lr_mordred.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
